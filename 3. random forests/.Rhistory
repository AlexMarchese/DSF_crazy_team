print('Hey guys')
library(tidyverse)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DS <- read.delim("../Data/dataset.csv",sep = ";")
View(DS)
DS <- DS %>% select(c(5, 7, 8, 9, 10, 11, 12, 14))
colnames(DS)[2] = "category"
View(DS)
colnames(DS)[2] = "category"
colnames(DS)[3] = "product_model"
colnames(DS)[2] = "type_of_picture"
library(tidyverse)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DS <- read.delim("../Data/dataset.csv",sep = ";")
DS <- DS %>% select(c(5, 7, 8, 9, 10, 11, 12, 14))
colnames(DS)[2] = "category"
colnames(DS)[3] = "product_model"
colnames(DS)[6] = "type_of_picture"
DS_unique <- unique(DS)
View(DS_unique)
library(tidyverse)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DS <- read.delim("../Data/dataset.csv",sep = ";")
DS <- DS %>% select(c(5, 7, 8, 9, 10, 11, 12, 14))
colnames(DS)[2] = "category"
colnames(DS)[3] = "product_model"
colnames(DS)[6] = "type_of_picture"
# DS_dupl <- DS %>% select(-country)
DS_unique <- unique(DS)
DS_unique$count <- 0
# class(DS_unique)
# lapply(DS_unique, class)
for (row in 0:nrow(DS_unique)) {
row <- 1
country<- DS_unique$country[row]
product_model<- DS_unique$product_model[row]
location<- DS_unique$location[row]
type_of_picture<- DS_unique$type_of_picture[row]
page<- DS_unique$page[row]
category<- DS_unique$category[row]
colour<- DS_unique$colour[row]
price<- DS_unique$price[row]
DS_unique$count[row] <- as.integer(count(DS[which(DS$category == category & DS$colour == colour & DS$price == price & DS$page == page & DS$type_of_picture == type_of_picture & DS$location == location & DS$product_model == product_model & DS$country == country),]))
}
final_DS <- DS_unique
write.csv(final_DS, "../Data/rearranged_extended_DS.csv")
DS_aggr <- read.csv("../Data/rearranged_extended_DS.csv") # rearranged extended dataset
DS_aggr_ext <- read.csv("../Data/rearranged_extended_DS.csv") # rearranged extended dataset
View(DS_aggr_ext)
library(tidyverse)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DS <- read.delim("../Data/dataset.csv",sep = ";")
DS <- DS %>% select(c(5, 7, 8, 9, 10, 11, 12, 14))
colnames(DS)[2] = "category"
colnames(DS)[3] = "product_model"
colnames(DS)[6] = "type_of_picture"
# DS_dupl <- DS %>% select(-country)
DS_unique <- unique(DS)
DS_unique$count <- 0
# class(DS_unique)
# lapply(DS_unique, class)
for (row in 0:nrow(DS_unique)) {
country<- DS_unique$country[row]
product_model<- DS_unique$product_model[row]
location<- DS_unique$location[row]
type_of_picture<- DS_unique$type_of_picture[row]
page<- DS_unique$page[row]
category<- DS_unique$category[row]
colour<- DS_unique$colour[row]
price<- DS_unique$price[row]
DS_unique$count[row] <- as.integer(count(DS[which(DS$category == category & DS$colour == colour & DS$price == price & DS$page == page & DS$type_of_picture == type_of_picture & DS$location == location & DS$product_model == product_model & DS$country == country),]))
}
final_DS <- DS_unique
write.csv(final_DS, "../Data/rearranged_extended_DS.csv")
DS_rearr <- read.csv("../Data/rearranged_DS.csv") # rearranged dataset
DS_rearr <- DS_rearr %>% select(-X)
DS_rearr_multiv <- DS_rearr # needed to do a multivariate classification later
med_3 <- median(DS_rearr$count)
DS_rearr <- DS_rearr %>% mutate(Label = ifelse(count >= med_3, 1, 0))
DS_rearr <- DS_rearr %>% select(-count)
View(DS_rearr)
DS_rearr <- read.csv("../Data/rearranged_DS.csv") # rearranged dataset
DS_rearr <- DS_rearr %>% select(-X)
DS_rearr_multiv <- DS_rearr
# packages needed
library(tidyverse)
library(caret)
library(nnet) # for multinomial logistic regression
library(glue) # this is a python f string equivalent -> needed for nice output printing
# clean environment and set current wd -> helps to easier work with imported files
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# three types of dataset (the original and two variations to see what gives best results)
DS_aggr_ext <- read.csv("../Data/rearranged_extended_DS.csv") # rearranged extended dataset
DS_aggr_ext <- DS_aggr_ext %>% select(-X)
med_4 <- median(DS_aggr$count)
DS_aggr_ext <- DS_aggr_ext %>% mutate(Label = ifelse(count >= med_4, 1, 0))
DS_aggr_ext <-DS_aggr_ext %>% select(-count)
DS_aggr_ext <- read.csv("../Data/rearranged_extended_DS.csv") # rearranged extended dataset
DS_aggr_ext <- DS_aggr_ext %>% select(-X)
med_4 <- median(DS_aggr_ext$count)
DS_aggr_ext <- DS_aggr_ext %>% mutate(Label = ifelse(count >= med_4, 1, 0))
DS_aggr_ext <-DS_aggr_ext %>% select(-count)
# function to do it quickly
misclass_calc <- function(type_DS, dataset) {
modelAll = glm(Label ~ ., family = "binomial", data = dataset)
predict(modelAll, type = "response")
D = dataset %>%
mutate(probAll = predict(modelAll, type = "response")) %>%
mutate(predAll50 = ifelse(probAll >=0.5, 1, 0))
misClas = mean(D$predAll50 != D$Label)
falPos =
length(which(D$Label == 0 & D$predAll50 == 1))/
length(which(D$Label == 0))
falNeg =
length(which(D$Label == 1 & D$predAll50 == 0))/
length(which(D$Label == 1))
return(glue("Dataset: {type_DS} dataset, misclassification: {round(misClas, digits=3)}, FP: {round(falPos, digits=3)}, FN: {round(falNeg, digits=3)}"))
}
misclass_calc("rearranged extended", DS_aggr_ext)
# packages needed
library(tidyverse)
library(caret)
library(nnet) # for multinomial logistic regression
library(glue) # this is a python f string equivalent -> needed for nice output printing
# clean environment and set current wd -> helps to easier work with imported files
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# three types of dataset (the original and two variations to see what gives best results)
# 1. binary approach
DS_or <- read.delim("../Data/dataset.csv",sep = ";") # original dataset
med_1 <- median(DS_or$order)
DS_or <- DS_or %>% mutate(Label = ifelse(order >= med_1, 1, 0))
DS_or <-DS_or %>% select(-order)
DS_aggr <- read.csv("../Data/clean_DS.csv") # aggregated dataset
DS_aggr <- DS_aggr %>% select(-X)
DS_aggr_dive_in <- DS_aggr # needed to see insights later
med_2 <- median(DS_aggr$visits)
DS_aggr <- DS_aggr %>% mutate(Label = ifelse(visits >= med_2, 1, 0))
DS_aggr <-DS_aggr %>% select(-visits)
DS_rearr <- read.csv("../Data/rearranged_DS.csv") # rearranged dataset
DS_rearr <- DS_rearr %>% select(-X)
DS_rearr_multiv <- DS_rearr # needed to do a multivariate classification later
med_3 <- median(DS_rearr$count)
DS_rearr <- DS_rearr %>% mutate(Label = ifelse(count >= med_3, 1, 0))
DS_rearr <- DS_rearr %>% select(-count)
DS_aggr_ext <- read.csv("../Data/rearranged_extended_DS.csv") # rearranged extended dataset
DS_aggr_ext <- DS_aggr_ext %>% select(-X)
med_4 <- median(DS_aggr_ext$count)
DS_aggr_ext <- DS_aggr_ext %>% mutate(Label = ifelse(count >= med_4, 1, 0))
DS_aggr_ext <-DS_aggr_ext %>% select(-count)
# for each dataset: fitting the model, predicting & calculating the misclassification
# function to do it quickly
misclass_calc <- function(type_DS, dataset) {
modelAll = glm(Label ~ ., family = "binomial", data = dataset)
predict(modelAll, type = "response")
D = dataset %>%
mutate(probAll = predict(modelAll, type = "response")) %>%
mutate(predAll50 = ifelse(probAll >=0.5, 1, 0))
misClas = mean(D$predAll50 != D$Label)
falPos =
length(which(D$Label == 0 & D$predAll50 == 1))/
length(which(D$Label == 0))
falNeg =
length(which(D$Label == 1 & D$predAll50 == 0))/
length(which(D$Label == 1))
return(glue("Dataset: {type_DS} dataset, misclassification: {round(misClas, digits=3)}, FP: {round(falPos, digits=3)}, FN: {round(falNeg, digits=3)}"))
}
# running the function
misclass_calc("original", DS_or)
misclass_calc("aggregated ", DS_aggr)
misclass_calc("rearranged", DS_rearr)
misclass_calc("rearranged extended", DS_aggr_ext)
med_2_dive_in <- median(DS_aggr_dive_in$visits)
hist(DS_aggr_dive_in$visits, xlab = "visits per customer", main = "frequency of visits per customer")
# taking out the outliers can be quite interesting, to see how the three metrics change. Let us keep all values <= 15
DS_aggr_dive_in = DS_aggr_dive_in %>%
filter(visits <= 15)
DS_aggr_dive_in <- DS_aggr_dive_in %>% mutate(Label = ifelse(visits >= med_2_dive_in, 1, 0)) # n.b. I am not changing the median value
DS_aggr_dive_in <-DS_aggr_dive_in %>% select(-visits)
misclass_calc("aggregated without outliers ", DS_aggr_dive_in)
# As can be seen, this helped getting a better balance between FP and FP. However it made the model worse overall
# After having analyzed the three datasets with a binary logistic regression, it can be concluded that the
# third dataset, which focuses on the variables price, category and colour, works best four our algorithm.
# Now that this was chosen, we can look into applying the CV for better comparison with other models, as
# it allows us to estimate the testing error
library(ranger)
library(rsample)
library(dplyr)
library(tidyverse)
library(randomForest)
library(magrittr)
library(caret)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#The test was done for all three data
M = read.csv("../Data/clean_DS.csv")
View(M)
M = read.csv("../Data/rearranged_extended_DS.csv")
View(M)
M$count = "visits"
names(M)[10] = "visits"
M = read.csv("../Data/rearranged_extended_DS.csv")
M = read.csv("../Data/rearranged_DS.csv")
View(M)
names(M)[5] = "visits"
#The test was done for all three data
M = read.csv("../Data/clean_DS.csv")
M = read.delim("../Data/dataset.csv",sep = ";")
library(ranger)
library(rsample)
library(dplyr)
library(tidyverse)
library(randomForest)
library(magrittr)
library(caret)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#The test was done for all three data
M = read.csv("../Data/clean_DS.csv")
M = read.csv("../Data/rearranged_DS.csv")
names(M)[5] = "visits"
M = read.csv("../Data/rearranged_extended_DS.csv")
names(M)[10] = "visits"
M = M %>%
select(-X)
M = read.delim("../Data/dataset.csv",sep = ";")
names(M)[4] = "visits"
M$date = paste0(M$year,"0",M$month,M$day)
M$date = as.Date(M$date, tryFormats = "%Y%m%d")
M = M %>%
select(-year,-month,-day)
hist(M$visits)
#Using the boxplot to exclude the extreme value (over 38)
ggplot()+geom_boxplot(aes(M$visits))
M_split <- initial_split(M, prop = .7)
M_train <- training(M_split)
M_test  <- testing(M_split)
m1 <- ranger(
formula = visits ~ .,
data    = M_train,
num.trees = 800,
mtry = NULL,
importance = "impurity",
min.node.size = 5,
sample.fraction = 0.8
)
"For the rearranged data with formula =count~. and
For the clean_DS, formula = visits~.
m1 <- ranger(
formula = count ~ .,
data    = M_train,
num.trees = 800,
mtry = NULL,
min.node.size = 5,
sample.fraction = 0.8
)
"
# WIth lower bound and upper bound both means are almost the same around 18
mean(M_train$visits)
mean(M_train$visits)
mean(m1$predictions)
m1$r.squared
caret::MAE(m1$predictions, M_train$visits)
caret::RMSE(m1$predictions, M_train$visits)
#manually is the same
mean(abs(M_train$visits - m1$predictions))
#with the clean Data I wouldn't take 10 mtry because it is like bagging
Matrixforloop <- expand.grid(
mtry       = seq(2,10, by = 2),
node_size  = seq(3, 9, by = 2),
sampe_size = c(.55, .632, .70, .80),
OOB_RMSE   = 0
)
for(i in 1:nrow(Matrixforloop)) {
m12 <- ranger(
formula         = visits ~ .,
data            = M_train,
num.trees       = 800,
mtry            = Matrixforloop$mtry[i],
min.node.size   = Matrixforloop$node_size[i],
sample.fraction = Matrixforloop$sampe_size[i],
seed            = 123
)
Matrixforloop$OOB_RMSE[i] <- sqrt(m12$prediction.error)
}
Matrixforloop %>%
dplyr::arrange(OOB_RMSE) %>%
head(10)
OOB_RMSE <- vector(mode = "numeric", length = 100)
library(ranger)
library(rsample)
library(dplyr)
library(tidyverse)
library(randomForest)
library(magrittr)
library(caret)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#The test was done for all three data
M = read.csv("../Data/clean_DS.csv")
M = read.csv("../Data/rearranged_DS.csv")
names(M)[5] = "visits"
M = read.csv("../Data/rearranged_extended_DS.csv")
names(M)[10] = "visits"
M = M %>%
select(-X)
M = read.delim("../Data/dataset.csv",sep = ";")
names(M)[4] = "visits"
M$date = paste0(M$year,"0",M$month,M$day)
M$date = as.Date(M$date, tryFormats = "%Y%m%d")
M = M %>%
select(-year,-month,-day)
hist(M$visits)
#Trying to exclude outlier
#M = M %>%
##  filter(visits>10) %>%
#  filter(visits< 38)
#Using the boxplot to exclude the extreme value (over 38)
ggplot()+geom_boxplot(aes(M$visits))
M_split <- initial_split(M, prop = .7)
M_train <- training(M_split)
M_test  <- testing(M_split)
#my first random forest
m1 <- ranger(
formula = visits ~ .,
data    = M_train,
num.trees = 800,
mtry = NULL,
importance = "impurity",
min.node.size = 5,
sample.fraction = 0.8
)
"For the rearranged data with formula =count~. and
For the clean_DS, formula = visits~.
m1 <- ranger(
formula = count ~ .,
data    = M_train,
num.trees = 800,
mtry = NULL,
min.node.size = 5,
sample.fraction = 0.8
)
"
#Initial data/ RSME: 10.41 MAE: 6.78 Mean: 9.81
#Clean data/ RSME:7.28 MAE:3.64 Mean: 6.9
#For the rearranged data Mean: 51.15, MAE: 41.15 RSME 117.53
# WIth lower bound and upper bound both means are almost the same around 18
mean(M_train$visits)
mean(M_train$visits)
mean(m1$predictions)
m1$r.squared
#0.407 for initial
#0.6 for the rearranged
#0.2 for the clean data
# The folowing is to high is too high
caret::MAE(m1$predictions, M_train$visits)
caret::RMSE(m1$predictions, M_train$visits)
#manually is the same
mean(abs(M_train$visits - m1$predictions))
#Compare to the mean is extremely high in all cases
#Increase mtry increase the result but it id still very high
#But if mtry is too high the risk to have corrolated trees also increase
#With so bad results, optimisation of the forest cannot make miracles
#with a loop through node.size, mtry, sample.fraction
#My loop would go through this:
#with the clean Data I wouldn't take 10 mtry because it is like bagging
Matrixforloop <- expand.grid(
mtry       = seq(2,10, by = 2),
node_size  = seq(3, 9, by = 2),
sampe_size = c(.55, .632, .70, .80),
OOB_RMSE   = 0
)
for(i in 1:nrow(Matrixforloop)) {
m12 <- ranger(
formula         = visits ~ .,
data            = M_train,
num.trees       = 800,
mtry            = Matrixforloop$mtry[i],
min.node.size   = Matrixforloop$node_size[i],
sample.fraction = Matrixforloop$sampe_size[i],
seed            = 123
)
Matrixforloop$OOB_RMSE[i] <- sqrt(m12$prediction.error)
}
